{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2P9H2ubS5msc"
      },
      "outputs": [],
      "source": [
        "#@title Check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-4eVF_7T_YF"
      },
      "outputs": [],
      "source": [
        "#@title Setup 1 (just run this once).\n",
        "import os\n",
        "import glob\n",
        "!git clone https://github.com/effusiveperiscope/so-vits-svc -b eff-4.0\n",
        "os.chdir('so-vits-svc')\n",
        "# install requirements one-at-a-time to ignore exceptions\n",
        "!cat requirements.txt | xargs -n 1 pip install --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install praat-parselmouth\n",
        "!pip install ipywidgets\n",
        "!pip install huggingface_hub\n",
        "!pip install pip==23.0.1 # fix pip version for fairseq install\n",
        "!pip install fairseq==0.12.2\n",
        "!pip uninstall -y matplotlib\n",
        "!pip install --no-cache-dir matplotlib\n",
        "!jupyter nbextension enable --py widgetsnbextension\n",
        "existing_files = glob.glob('/content/**/*.*', recursive=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7aE5WZqdStA"
      },
      "outputs": [],
      "source": [
        "#@title Setup 2 (just run this once)\n",
        "import os\n",
        "os.chdir('/content/so-vits-svc') # force working-directory to so-vits-svc - this line is just for safety and is probably not required\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from pathlib import Path\n",
        "import tarfile\n",
        "import gdown\n",
        "import urllib\n",
        "import os\n",
        "import subprocess\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "class Downloader2:\n",
        "    LINUX_MEGATOOLS_URL = (\"https://megatools.megous.com/builds/builds/\"\n",
        "        \"megatools-1.11.1.20230212-linux-x86_64.tar.gz\")\n",
        "    def __init__(self):\n",
        "        self.mega_setup()\n",
        "        pass\n",
        "\n",
        "    def mega_setup(self):\n",
        "        MEGATOOLS_TAR_PATH = Downloader2.LINUX_MEGATOOLS_URL.split(\"/\")[-1]\n",
        "        MEGATOOLS_FOLDER_PATH = (\n",
        "            Downloader2.LINUX_MEGATOOLS_URL.split(\"/\")[-1].removesuffix(\n",
        "                \".tar.gz\"))\n",
        "        self.abs_megatools_path = os.path.abspath(MEGATOOLS_FOLDER_PATH)\n",
        "\n",
        "        urllib.request.urlretrieve(\n",
        "            url=Downloader2.LINUX_MEGATOOLS_URL,\n",
        "            filename=MEGATOOLS_TAR_PATH)\n",
        "        with tarfile.open(MEGATOOLS_TAR_PATH) as tar:\n",
        "            tar.extractall()\n",
        "            tar.close()\n",
        "        os.unlink(MEGATOOLS_TAR_PATH)\n",
        "        assert os.path.exists(self.abs_megatools_path)\n",
        "\n",
        "        pass\n",
        "\n",
        "    def megadown(self, url, filename):\n",
        "        cmd = (os.path.join(self.abs_megatools_path,'megatools')+\n",
        "            \" dl \"+\"--print-names \"+(\n",
        "            \"--path \"+filename+\" \" if filename else \"\")+url)\n",
        "        proc = subprocess.run(cmd, shell=True)\n",
        "        if proc.returncode != 0:\n",
        "            raise Exception('megadown failed -- cmd: '+cmd)\n",
        "        return filename\n",
        "\n",
        "    def request_url_with_progress_bar(self, url, filename):\n",
        "        def download_url(url, filename):\n",
        "            with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                miniters=1, desc=url.split('/')[-1]) as t:\n",
        "                return urllib.request.urlretrieve(\n",
        "                    url, filename=filename, reporthook=t.update_to)\n",
        "        return download_url(url, filename)\n",
        "\n",
        "    def download(self, url, filename):\n",
        "        if \"https://drive.google.com/uc?id=\" in url:\n",
        "            print(\"Downloading Google Drive file \"+url)\n",
        "            return gdown.download(url, filename, quiet=False)\n",
        "        elif \"mega.nz\" in url:\n",
        "            print(\"Downloading MEGA file \"+url)\n",
        "            # There is no other way to determine the file name\n",
        "            # from megatools prior to downloading without authentication\n",
        "            # so we set it to a placeholder\n",
        "            import uuid\n",
        "            return self.megadown(url, filename=str(uuid.uuid4())+\".zip\")\n",
        "        else:\n",
        "            print(\"Downloading direct \"+url)\n",
        "            local_filename, headers = (\n",
        "                self.request_url_with_progress_bar(url, filename))\n",
        "            return local_filename\n",
        "\n",
        "\n",
        "import fnmatch\n",
        "def default_next(x):\n",
        "    try:\n",
        "        return next(x)\n",
        "    except StopIteration:\n",
        "        return None\n",
        "    \n",
        "def zip_extract(zipfile, model_dir):\n",
        "    model_folder_name = Path(zipfile).stem\n",
        "    model_folder_path = os.path.join(model_dir,\n",
        "        Path(zipfile).stem)\n",
        "    with ZipFile(zipfile, 'r') as f:\n",
        "        member_infos = f.infolist()\n",
        "        generator = default_next(\n",
        "            x for x in member_infos if fnmatch.fnmatch(x.filename, '*G_*.pth'))\n",
        "        config_json = default_next(\n",
        "            x for x in member_infos if fnmatch.fnmatch(x.filename, '*.json'))\n",
        "        cluster_pt = default_next(\n",
        "            x for x in member_infos if fnmatch.fnmatch(x.filename, '*.pt'))\n",
        "\n",
        "        generator.filename = generator.filename.split('/')[-1]\n",
        "        config_json.filename = config_json.filename.split('/')[-1]\n",
        "\n",
        "        if (not generator):\n",
        "            print(\"Could not find G_*.pth in \"+zipfile)\n",
        "            return\n",
        "        if (not config_json):\n",
        "            print(\"Could not find config.json in \"+zipfile)\n",
        "            return\n",
        "        f.extract(generator, path=model_folder_path)\n",
        "        f.extract(config_json, path=model_folder_path)\n",
        "\n",
        "        if cluster_pt:\n",
        "            cluster_pt.filename = cluster_pt.filename.split('/')[-1]\n",
        "            f.extract(cluster_pt, path=model_folder_path)\n",
        "    print(\"Cleaning \"+zipfile)\n",
        "    os.remove(zipfile)\n",
        "\n",
        "import huggingface_hub\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "class HFModels:\n",
        "    def __init__(self, repo = \"therealvul/so-vits-svc-4.0\", \n",
        "            model_dir = \"hf_vul_models\"):\n",
        "        self.model_repo = huggingface_hub.Repository(local_dir=model_dir,\n",
        "            clone_from=repo, skip_lfs_files=True)\n",
        "        self.repo = repo\n",
        "        self.model_dir = model_dir\n",
        "\n",
        "        self.model_folders = sorted(os.listdir(model_dir))\n",
        "        print(self.model_folders)\n",
        "        self.model_folders.remove('.git')\n",
        "        self.model_folders.remove('.gitattributes')\n",
        "\n",
        "    def list_models(self):\n",
        "        return self.model_folders\n",
        "\n",
        "    # Downloads model;\n",
        "    # copies config to target_dir and moves model to target_dir\n",
        "    def download_model(self, model_name, target_dir):\n",
        "        if not model_name in self.model_folders:\n",
        "            raise Exception(model_name + \" not found\")\n",
        "        model_dir = self.model_dir\n",
        "        charpath = os.path.join(model_dir,model_name)\n",
        "\n",
        "        gen_pt = next(x for x in os.listdir(charpath) if x.startswith(\"G_\"))\n",
        "        cfg = next(x for x in os.listdir(charpath) if x.endswith(\"json\"))\n",
        "        try:\n",
        "          clust = next(x for x in os.listdir(charpath) if x.endswith(\"pt\"))\n",
        "        except StopIteration as e:\n",
        "          print(\"Note - no cluster model for \"+model_name)\n",
        "          clust = None\n",
        "\n",
        "        if not os.path.exists(target_dir):\n",
        "            os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "        gen_dir = huggingface_hub.hf_hub_download(repo_id = self.repo,\n",
        "            filename = model_name + \"/\" + gen_pt) # this is a symlink\n",
        "        \n",
        "        if clust is not None:\n",
        "          clust_dir = huggingface_hub.hf_hub_download(repo_id = self.repo,\n",
        "              filename = model_name + \"/\" + clust) # this is a symlink\n",
        "          shutil.move(os.path.realpath(clust_dir), os.path.join(target_dir, clust))\n",
        "          clust_out = os.path.join(target_dir, clust)\n",
        "        else:\n",
        "          clust_out = None\n",
        "\n",
        "        shutil.copy(os.path.join(charpath,cfg),os.path.join(target_dir, cfg))\n",
        "        shutil.move(os.path.realpath(gen_dir), os.path.join(target_dir, gen_pt))\n",
        "\n",
        "        return {\"config_path\": os.path.join(target_dir,cfg),\n",
        "            \"generator_path\": os.path.join(target_dir,gen_pt),\n",
        "            \"cluster_path\": clust_out}\n",
        "\n",
        "# Example usage\n",
        "# vul_models = HFModels()\n",
        "# print(vul_models.list_models())\n",
        "# print(\"Applejack (singing)\" in vul_models.list_models())\n",
        "# vul_models.download_model(\"Applejack (singing)\",\"models/Applejack (singing)\")\n",
        "downloader = Downloader2()\n",
        "print(\"Finished!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JntsKHUGr9kD"
      },
      "outputs": [],
      "source": [
        "#@title Download ContentVec (just run this once)\n",
        "os.chdir('/content/so-vits-svc') # force working-directory to so-vits-svc - this line is just for safety and is probably not required\n",
        "downloader.download(\"https://huggingface.co/therealvul/so-vits-svc-4.0-init/resolve/main/checkpoint_best_legacy_500.pt\", filename=\"hubert/checkpoint_best_legacy_500.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ist9AYsybTc7"
      },
      "outputs": [],
      "source": [
        "#@title Setup HF Downloads (run cell and click buttons to download models)\n",
        "from ipywidgets import widgets\n",
        "vul_models = HFModels()\n",
        "\n",
        "def button_eventhandler(but):\n",
        "  vul_models.download_model(but.description, \"models/\"+but.description)\n",
        "\n",
        "for model in vul_models.list_models():\n",
        "  btn = widgets.Button(description=model)\n",
        "  btn.on_click(button_eventhandler)\n",
        "  display(btn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFr2MWaQfR6X"
      },
      "outputs": [],
      "source": [
        "#@title Other Downloads (.zip) Step o.1\n",
        "#@markdown Please note that 3.0 models are incompatible with 4.0.\n",
        "#@markdown After running this step, be sure to run the below step (o.2).\n",
        "\n",
        "#@markdown Supported URL types: \n",
        "#@markdown * Google Drive zip\n",
        "#@markdown * MEGA zip\n",
        "#@markdown * Direct zip (+HuggingFace /resolve/ link)\n",
        "\n",
        "import re\n",
        "model_url = \"https://mega.nz/file/P7hWwCoQ#s0OICnRbTpcUjUIS7iQPIlYwBVelZXzm_-1LLPSUd2Y\" #@param {\"type\": \"string\"}\n",
        "if \"huggingface.co\" in model_url.lower():\n",
        "  model_zip_path = downloader.download(re.sub(r\"/blob/\",\"/resolve/\",model_url), \n",
        "           filename=os.path.join(os.getcwd(),model_url.split(\"/\")[-1]))\n",
        "else:\n",
        "  model_zip_path = downloader.download(model_url, filename=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FHg8Gx8ihDk"
      },
      "outputs": [],
      "source": [
        "#@title Extract .zip Downloads - Step o.2\n",
        "# download speaker model files into 'models' directory\n",
        "import glob, os, shutil\n",
        "from pathlib import Path\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "zip_extract(model_zip_path, 'models')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApSNOxOJEWLN"
      },
      "source": [
        "**!!! Please restart the runtime before running the next cell !!!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bpg6Ql1QHEV6"
      },
      "outputs": [],
      "source": [
        "#@title Open the file explorer on the left of your screen and drag-and-drop an audio file anywhere. Then run the below cell.\n",
        "#@markdown If you get an error relating to numpy please restart the runtime. (Runtime > Restart runtime)\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import copy\n",
        "import logging\n",
        "import io\n",
        "from ipywidgets import widgets\n",
        "from pathlib import Path\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "os.chdir('/content/so-vits-svc')\n",
        "\n",
        "import torch\n",
        "from inference import infer_tool\n",
        "from inference import slicer\n",
        "from inference.infer_tool import Svc\n",
        "import soundfile\n",
        "import numpy as np\n",
        "\n",
        "MODELS_DIR = \"models\"\n",
        "\n",
        "def get_speakers():\n",
        "  speakers = []\n",
        "  for _,dirs,_ in os.walk(MODELS_DIR):\n",
        "    for folder in dirs:\n",
        "      cur_speaker = {}\n",
        "      # Look for G_****.pth\n",
        "      g = glob.glob(os.path.join(MODELS_DIR,folder,'G_*.pth'))\n",
        "      if not len(g):\n",
        "        print(\"Skipping \"+folder+\", no G_*.pth\")\n",
        "        continue\n",
        "      cur_speaker[\"model_path\"] = g[0]\n",
        "      cur_speaker[\"model_folder\"] = folder\n",
        "\n",
        "      # Look for *.pt (clustering model)\n",
        "      clst = glob.glob(os.path.join(MODELS_DIR,folder,'*.pt'))\n",
        "      if not len(clst):\n",
        "        print(\"Note: No clustering model found for \"+folder)\n",
        "        cur_speaker[\"cluster_path\"] = \"\"\n",
        "      else:\n",
        "        cur_speaker[\"cluster_path\"] = clst[0]\n",
        "\n",
        "      # Look for config.json\n",
        "      cfg = glob.glob(os.path.join(MODELS_DIR,folder,'*.json'))\n",
        "      if not len(cfg):\n",
        "        print(\"Skipping \"+folder+\", no config json\")\n",
        "        continue\n",
        "      cur_speaker[\"cfg_path\"] = cfg[0]\n",
        "      with open(cur_speaker[\"cfg_path\"]) as f:\n",
        "        try:\n",
        "          cfg_json = json.loads(f.read())\n",
        "        except Exception as e:\n",
        "          print(\"Malformed config json in \"+folder)\n",
        "        for name, i in cfg_json[\"spk\"].items():\n",
        "          cur_speaker[\"name\"] = name\n",
        "          cur_speaker[\"id\"] = i\n",
        "          if not name.startswith('.'):\n",
        "            speakers.append(copy.copy(cur_speaker))\n",
        "\n",
        "    return sorted(speakers, key=lambda x:x[\"name\"].lower())\n",
        "\n",
        "logging.getLogger('numba').setLevel(logging.WARNING)\n",
        "chunks_dict = infer_tool.read_temp(\"inference/chunks_temp.json\")\n",
        "existing_files = []\n",
        "slice_db = -40\n",
        "wav_format = 'wav'\n",
        "\n",
        "class InferenceGui():\n",
        "  def __init__(self):\n",
        "    self.speakers = get_speakers()\n",
        "    self.speaker_list = [x[\"name\"] for x in self.speakers]\n",
        "    self.speaker_box = widgets.Dropdown(\n",
        "        options = self.speaker_list\n",
        "    )\n",
        "    display(self.speaker_box)\n",
        "\n",
        "    def convert_cb(btn):\n",
        "      self.convert()\n",
        "    def clean_cb(btn):\n",
        "      self.clean()\n",
        "\n",
        "    self.convert_btn = widgets.Button(description=\"Convert\")\n",
        "    self.convert_btn.on_click(convert_cb)\n",
        "    self.clean_btn = widgets.Button(description=\"Delete all audio files\")\n",
        "    self.clean_btn.on_click(clean_cb)\n",
        "\n",
        "    self.trans_tx = widgets.IntText(value=12, description='Transpose')\n",
        "    self.cluster_ratio_tx = widgets.FloatText(value=0.0, \n",
        "      description='Clustering Ratio')\n",
        "    self.noise_scale_tx = widgets.FloatText(value=0.4, \n",
        "      description='Noise Scale')\n",
        "    self.auto_pitch_ck = widgets.Checkbox(value=False, description=\n",
        "      'Auto pitch f0 (do not use for singing)')\n",
        "\n",
        "    display(self.trans_tx)\n",
        "    display(self.cluster_ratio_tx)\n",
        "    display(self.noise_scale_tx)\n",
        "    display(self.auto_pitch_ck)\n",
        "    display(self.convert_btn)\n",
        "    display(self.clean_btn)\n",
        "\n",
        "  def convert(self):\n",
        "    trans = int(self.trans_tx.value)\n",
        "    speaker = next(x for x in self.speakers if x[\"name\"] == \n",
        "          self.speaker_box.value)\n",
        "    spkpth2 = os.path.join(os.getcwd(),speaker[\"model_path\"])\n",
        "    print(spkpth2)\n",
        "    print(os.path.exists(spkpth2))\n",
        "\n",
        "    svc_model = Svc(speaker[\"model_path\"], speaker[\"cfg_path\"], \n",
        "      cluster_model_path=speaker[\"cluster_path\"])\n",
        "    \n",
        "    input_filepaths = [f for f in glob.glob('/content/**/*.*', recursive=True)\n",
        "     if f not in existing_files and \n",
        "     any(f.endswith(ex) for ex in ['.wav','.flac','.mp3','.ogg','.opus'])]\n",
        "    for name in input_filepaths:\n",
        "      print(\"Converting \"+os.path.split(name)[-1])\n",
        "      infer_tool.format_wav(name)\n",
        "\n",
        "      wav_path = str(Path(name).with_suffix('.wav'))\n",
        "      wav_name = Path(name).stem\n",
        "      chunks = slicer.cut(wav_path, db_thresh=slice_db)\n",
        "      audio_data, audio_sr = slicer.chunks2audio(wav_path, chunks)\n",
        "\n",
        "      audio = []\n",
        "      for (slice_tag, data) in audio_data:\n",
        "          print(f'#=====segment start, '\n",
        "              f'{round(len(data)/audio_sr, 3)}s======')\n",
        "          \n",
        "          length = int(np.ceil(len(data) / audio_sr *\n",
        "              svc_model.target_sample))\n",
        "          \n",
        "          if slice_tag:\n",
        "              print('jump empty segment')\n",
        "              _audio = np.zeros(length)\n",
        "          else:\n",
        "              # Padding \"fix\" for noise\n",
        "              pad_len = int(audio_sr * 0.5)\n",
        "              data = np.concatenate([np.zeros([pad_len]),\n",
        "                  data, np.zeros([pad_len])])\n",
        "              raw_path = io.BytesIO()\n",
        "              soundfile.write(raw_path, data, audio_sr, format=\"wav\")\n",
        "              raw_path.seek(0)\n",
        "              _cluster_ratio = 0.0\n",
        "              if speaker[\"cluster_path\"] != \"\":\n",
        "                _cluster_ratio = float(self.cluster_ratio_tx.value)\n",
        "              out_audio, out_sr = svc_model.infer(\n",
        "                  speaker[\"name\"], trans, raw_path,\n",
        "                  cluster_infer_ratio = _cluster_ratio,\n",
        "                  auto_predict_f0 = bool(self.auto_pitch_ck.value),\n",
        "                  noice_scale = float(self.noise_scale_tx.value))\n",
        "              _audio = out_audio.cpu().numpy()\n",
        "              pad_len = int(svc_model.target_sample * 0.5)\n",
        "              _audio = _audio[pad_len:-pad_len]\n",
        "          audio.extend(list(infer_tool.pad_array(_audio, length)))\n",
        "          \n",
        "      res_path = os.path.join('/content/',\n",
        "          f'{wav_name}_{trans}_key_'\n",
        "          f'{speaker[\"name\"]}.{wav_format}')\n",
        "      soundfile.write(res_path, audio, svc_model.target_sample,\n",
        "          format=wav_format)\n",
        "      display(Audio(res_path, autoplay=True)) # display audio file\n",
        "    pass\n",
        "\n",
        "  def clean(self):\n",
        "     input_filepaths = [f for f in glob.glob('/content/**/*.*', recursive=True)\n",
        "     if f not in existing_files and \n",
        "     any(f.endswith(ex) for ex in ['.wav','.flac','.mp3','.ogg','.opus'])]\n",
        "     for f in input_filepaths:\n",
        "       os.remove(f)\n",
        "\n",
        "inference_gui = InferenceGui()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Uo9knXk-0s"
      },
      "source": [
        "Changelog\n",
        "\n",
        "*   3/31: possible fix for mega zip downloads\n",
        "*   4/14: possible more robust downloads\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
